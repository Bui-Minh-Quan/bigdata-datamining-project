import logging 
from datetime import date, datetime, timedelta
import time 
import sys
import os
import re 
import importlib

# ThÃªm Ä‘Æ°á»ng dáº«n project vÃ o path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from database.db import get_database

# --- IMPORTS ---
from crawling.news_daily_crawl import main_news_crawling
from crawling.posts_daily_crawl import main_posts_crawling
# Import Data Loader má»›i
from crawling.data_loader import fetch_recent_data_online

try:
    from etl.summarizer import run_summarization
except ImportError:
    print("âš ï¸ Warning: ChÆ°a tÃ¬m tháº¥y module 'etl.summarizer'. BÆ°á»›c tÃ³m táº¯t cÃ³ thá»ƒ bá»‹ lá»—i.")
    def run_summarization(date): pass 

from etl.graph_loader import save_graph
from etl.memory_attention import TRRMemoryAttention
from etl.reasoning import StockPredictor
from etl.extractor import build_daily_knowledge_graph_batch

# Danh má»¥c Ä‘áº§u tÆ°
PORTFOLIO_STOCKS = ["FPT", "SSI", "VCB", "VHM", "HPG", "GAS", "MSN", "MWG", "GVR", "VIC"]

def parse_llm_response(response_text):
    """HÃ m tÃ¡ch chuá»—i text cá»§a Gemini"""
    if not response_text:
        return "UNKNOWN", "0%", "KhÃ´ng cÃ³ dá»¯ liá»‡u phÃ¢n tÃ­ch"
    
    trend_match = re.search(r"\[TREND\]:\s*(.*)", response_text, re.IGNORECASE)
    conf_match = re.search(r"\[CONFIDENCE\]:\s*(.*)", response_text, re.IGNORECASE)
    reason_match = re.search(r"\[REASONING\]:\s*((?:.|\n)*)", response_text, re.IGNORECASE)
    
    trend = trend_match.group(1).strip().upper() if trend_match else "UNKNOWN"
    confidence = conf_match.group(1).strip() if conf_match else "0%"
    reasoning = reason_match.group(1).strip() if reason_match else response_text
    
    return trend, confidence, reasoning

def save_predictions_to_db(results, target_date_str):
    """LÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ o MongoDB"""
    print("\nğŸ’¾ Äang lÆ°u káº¿t quáº£ dá»± Ä‘oÃ¡n vÃ o MongoDB...")
    db = get_database()
    collection = db['stock_predictions']
    timestamp = datetime.now()
    count = 0
    
    for ticker, full_text in results.items():
        if not full_text: continue
        trend, confidence, reasoning = parse_llm_response(full_text)
        record = {
            "date": target_date_str,
            "symbol": ticker,
            "full_analysis": full_text,
            "trend": trend,
            "confidence": confidence,
            "reasoning": reasoning,
            "created_at": timestamp
        }
        collection.update_one(
            {"date": target_date_str, "symbol": ticker},
            {"$set": record},
            upsert=True
        )
        count += 1
    print(f"âœ… ÄÃ£ lÆ°u thÃ nh cÃ´ng {count} dá»± Ä‘oÃ¡n vÃ o collection 'stock_predictions'")

# --- HÃ€M CHáº Y PIPELINE CHÃNH ---
def run_full_pipeline(target_date_input=None, progress_callback=None):
    """
    Cháº¡y toÃ n bá»™ quy trÃ¬nh phÃ¢n tÃ­ch.
    progress_callback: HÃ m callback Ä‘á»ƒ cáº­p nháº­t tiáº¿n Ä‘á»™ lÃªn UI (optional)
    """
    # Náº¿u khÃ´ng truyá»n ngÃ y, máº·c Ä‘á»‹nh lÃ  hÃ´m nay
    if target_date_input is None:
        target_date_input = datetime.now().strftime("%Y-%m-%d")

    # Chuáº©n hÃ³a ngÃ y thÃ¡ng
    if isinstance(target_date_input, str):
        try:
            target_date_str = target_date_input
            target_date_obj = datetime.strptime(target_date_input, "%Y-%m-%d").date()
        except ValueError:
            return {"status": "error", "message": "NgÃ y khÃ´ng há»£p lá»‡"}
    else:
        target_date_obj = target_date_input
        target_date_str = target_date_input.strftime("%Y-%m-%d")

    def update_status(msg, percent):
        print(msg)
        if progress_callback: progress_callback(msg, percent)

    print(f"\n{'='*50}")
    print(f"ğŸš€ Báº®T Äáº¦U PIPELINE NGÃ€Y {target_date_str}")
    print(f"{'='*50}\n")
    
    # BÆ¯á»šC 0: Cáº¬P NHáº¬T GIÃ (Má»šI THÃŠM)
    update_status("ğŸ“‰ BÆ°á»›c 0: Cáº­p nháº­t dá»¯ liá»‡u giÃ¡ má»›i nháº¥t...", 10)
    try:
        fetch_recent_data_online()
    except Exception as e:
        print(f"âš ï¸ Lá»—i cáº­p nháº­t giÃ¡: {e}")

    # BÆ¯á»šC 1: CRAWL TIN Tá»¨C
    update_status("ğŸ“° BÆ°á»›c 1: Thu tháº­p dá»¯ liá»‡u tin tá»©c & máº¡ng xÃ£ há»™i...", 30)
    try:
        main_posts_crawling(target_date_obj)
        main_news_crawling(target_date_obj)
    except Exception as e:
        print(f"âš ï¸ Lá»—i Crawling: {e}")
    
    # BÆ¯á»šC 2: TÃ“M Táº®T & XÃ‚Y GRAPH
    update_status("ğŸ§  BÆ°á»›c 2: TÃ³m táº¯t vÃ  xÃ¢y dá»±ng Ä‘á»“ thá»‹ tri thá»©c...", 50)
    run_summarization()
    
    daily_graph = build_daily_knowledge_graph_batch(target_date_str)
    
    # BÆ¯á»šC 3: TÃCH Há»¢P NEO4J
    update_status("ğŸ’¾ BÆ°á»›c 3: LÆ°u trá»¯ vÃ o Neo4j...", 70)
    if daily_graph.number_of_nodes() > 0:
        save_graph(daily_graph)
    
    # BÆ¯á»šC 4: TRR MEMORY
    update_status("ğŸ” BÆ°á»›c 4: KÃ­ch hoáº¡t TRR Memory & Attention...", 80)
    trr = TRRMemoryAttention()
    G_full = trr.fetch_historical_graph(target_date_str)
    G_attention = trr.apply_attention_mechanism(G_full, PORTFOLIO_STOCKS)
    graph_context = trr.format_graph_for_llm(G_attention)
    trr.close()
    
    if not graph_context:
        graph_context = "KhÃ´ng cÃ³ sá»± kiá»‡n quan trá»ng nÃ o."
    
    # BÆ¯á»šC 5: Dá»° ÄOÃN (LLM)
    update_status("ğŸ”® BÆ°á»›c 5: AI Ä‘ang suy luáº­n & dá»± Ä‘oÃ¡n...", 90)
    predictor = StockPredictor()
    results = {}
    
    for ticker in PORTFOLIO_STOCKS:
        prediction = predictor.predict(ticker=ticker, graph_context=graph_context, target_date=target_date_str)
        results[ticker] = prediction
        print(f"Prediction for {ticker}:\n{prediction}\n{'-'*30}\n")
        
        # time.sleep(1) # Giáº£m delay Ä‘á»ƒ nhanh hÆ¡n

    # BÆ¯á»šC 6: LÆ¯U Káº¾T QUáº¢
    save_predictions_to_db(results, target_date_str)

    update_status(f"âœ… HoÃ n thÃ nh phÃ¢n tÃ­ch ngÃ y {target_date_str}!", 100)
    return results

if __name__ == "__main__":
    today = datetime.now().strftime("%Y-%m-%d")
    run_full_pipeline(today)