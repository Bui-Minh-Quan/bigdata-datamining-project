import logging 
from datetime import date, datetime, timedelta
import time 
import sys
import os

from database.db import get_database

# --- 1. CRAWLING IMPORTS ---
# Äáº£m báº£o tÃªn hÃ m khá»›p vá»›i file trong folder crawling
from crawling.news_daily_crawl import main_news_crawling
from crawling.posts_daily_crawl import main_posts_crawling

# --- 2. ETL IMPORTS ---
# Kiá»ƒm tra import summarizer (giáº£ sá»­ báº¡n Ä‘Ã£ cÃ³ file nÃ y)
try:
    from etl.summarizer import run_summarization
except ImportError:
    print("âš ï¸ Warning: ChÆ°a tÃ¬m tháº¥y module 'etl.summarizer'. BÆ°á»›c tÃ³m táº¯t cÃ³ thá»ƒ bá»‹ lá»—i.")
    def run_summarization(date): pass 

from etl.graph_loader import save_graph
from etl.memory_attention import TRRMemoryAttention
from etl.reasoning import StockPredictor
from etl.extractor import build_daily_knowledge_graph_batch

# Danh má»¥c Ä‘áº§u tÆ°
PORTFOLIO_STOCKS = ["FPT", "SSI", "VCB", "VHM", "HPG", "GAS", "MSN", "MWG", "GVR", "VIC"]

def run_full_pipeline(target_date_input):
    # --- CHUáº¨N HÃ“A NGÃ€Y THÃNG (Quan trá»ng) ---
    # Táº¡o 2 biáº¿n: 1 cho DB (String), 1 cho Logic (Date Obj)
    if isinstance(target_date_input, str):
        try:
            target_date_str = target_date_input
            target_date_obj = datetime.strptime(target_date_input, "%Y-%m-%d").date()
        except ValueError:
            print(f"âŒ Lá»—i: NgÃ y '{target_date_input}' khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng YYYY-MM-DD")
            return
    elif isinstance(target_date_input, (date, datetime)):
        target_date_obj = target_date_input
        target_date_str = target_date_input.strftime("%Y-%m-%d")
    else:
        print("âŒ Lá»—i: Input ngÃ y khÃ´ng há»£p lá»‡.")
        return

    print(f"\n{'='*50}")
    print(f"ğŸš€ Báº®T Äáº¦U PIPELINE NGÃ€Y {target_date_str}")
    print(f"{'='*50}\n")
    
    # ---------------------------------------------------------
    # 1. Crawling news and posts
    # ---------------------------------------------------------
    print("ğŸ“° BÆ°á»›c 1: Thu tháº­p dá»¯ liá»‡u tá»« máº¡ng xÃ£ há»™i vÃ  tin tá»©c...")
    # Crawler Ä‘Ã£ Ä‘Æ°á»£c sá»­a Ä‘á»ƒ nháº­n cáº£ string láº«n date object, nhÆ°ng truyá»n object an toÃ n hÆ¡n
    main_posts_crawling(target_date_obj)
    main_news_crawling(target_date_obj)
    
    # ---------------------------------------------------------
    # 2. Summarization and Graph Construction
    # ---------------------------------------------------------
    print("\nğŸ§  BÆ°á»›c 2: TÃ³m táº¯t vÃ  xÃ¢y dá»±ng Ä‘á»“ thá»‹ tri thá»©c...")
    
    # BÆ°á»›c nÃ y thÆ°á»ng dÃ¹ng MongoDB query string
    run_summarization()
    db = get_database()
    summ_count = db['summarized_news'].count_documents({"date": target_date_str})
    print(f"ğŸ“Š Kiá»ƒm tra MongoDB: TÃ¬m tháº¥y {summ_count} bÃ i bÃ¡o Ä‘Ã£ tÃ³m táº¯t cho ngÃ y {target_date_str}")
    
    # Extractor dÃ¹ng string cho MongoDB
    daily_graph = build_daily_knowledge_graph_batch(target_date_str)
    
    # ---------------------------------------------------------
    # 3. Integrate with historical graph from Neo4j
    # ---------------------------------------------------------
    print("\nğŸ’¾ BÆ°á»›c 3: LÆ°u trá»¯ vÃ  TÃ­ch há»£p Ä‘á»“ thá»‹ tri thá»©c Lá»‹ch sá»­")
    if daily_graph.number_of_nodes() > 0:
        save_graph(daily_graph)
    else:
        print("âš ï¸ Äá»“ thá»‹ tri thá»©c hÃ´m nay rá»—ng. Váº«n tiáº¿p tá»¥c Ä‘á»ƒ láº¥y dá»¯ liá»‡u quÃ¡ khá»©.")
    
    # ---------------------------------------------------------
    # 4. MEMORY & ATTENTION (TRR)
    # ---------------------------------------------------------
    print("\nğŸ” BÆ°á»›c 4: KÃ­ch hoáº¡t TRR Memory & Attention...")
    trr = TRRMemoryAttention()
    
    # Fetch graph quÃ¡ khá»© (dÃ¹ng string date)
    G_full = trr.fetch_historical_graph(target_date_str)
    
    # Ãp dá»¥ng PageRank Ä‘á»ƒ lá»c
    G_attention = trr.apply_attention_mechanism(G_full, PORTFOLIO_STOCKS)
    
    # Format ra text cho LLM
    graph_context = trr.format_graph_for_llm(G_attention)
    trr.close()
    
    if not graph_context:
        graph_context = "KhÃ´ng cÃ³ sá»± kiá»‡n quan trá»ng nÃ o trong Ä‘á»“ thá»‹ tri thá»©c."
        print("   -> Context rá»—ng.")
    else:
        print(f"   -> Context generated ({len(graph_context)} chars).")
    
    # ---------------------------------------------------------
    # 5. Prediction
    # ---------------------------------------------------------
    print("\nğŸ”® BÆ°á»›c 5: Dá»± Ä‘oÃ¡n xu hÆ°á»›ng (Predictor)...")
    predictor = StockPredictor()
    results = {}
    
    print(f"\nğŸ“ Context máº«u gá»­i cho LLM:\n{graph_context[:300]}...\n")

    for ticker in PORTFOLIO_STOCKS:
        print(f"--- PhÃ¢n tÃ­ch {ticker} ---")
        # Predictor cáº§n string date Ä‘á»ƒ láº¥y sentiment tá»« MongoDB
        prediction = predictor.predict(ticker, target_date_str, graph_context)
        
        print(f"   ğŸ‘‰ Káº¿t quáº£: {prediction}\n")
        results[ticker] = prediction
        
        # Nghá»‰ nháº¹ Ä‘á»ƒ trÃ¡nh rate limit
        time.sleep(1)

    print(f"\nâœ… HOÃ€N THÃ€NH PIPELINE NGÃ€Y {target_date_str}")
    return results

if __name__ == "__main__":
    # Báº¡n cÃ³ thá»ƒ truyá»n chuá»—i YYYY-MM-DD vÃ o Ä‘Ã¢y thoáº£i mÃ¡i
    run_full_pipeline("2025-11-20")