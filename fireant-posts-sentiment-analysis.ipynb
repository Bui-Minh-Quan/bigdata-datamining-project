{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13711106,"sourceType":"datasetVersion","datasetId":8722562}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:39.446427Z","iopub.execute_input":"2025-11-13T09:33:39.447073Z","iopub.status.idle":"2025-11-13T09:33:39.450819Z","shell.execute_reply.started":"2025-11-13T09:33:39.447046Z","shell.execute_reply":"2025-11-13T09:33:39.449930Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/all-posts/all_posts.csv', nrows=1000000)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:39.451928Z","iopub.execute_input":"2025-11-13T09:33:39.452707Z","iopub.status.idle":"2025-11-13T09:33:43.234164Z","shell.execute_reply.started":"2025-11-13T09:33:39.452682Z","shell.execute_reply":"2025-11-13T09:33:43.233204Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"    postID                                    originalContent        date  \\\n0  3118126  V√†o NKG ng√†y mai ·ªïn kh√¥ng c√°c b√°c? D√†i h·∫°n v√†o...  2021-09-30   \n1  3118104  C√≥ m·ªôt ƒëi·ªÅu th·∫•y bu·ªìn c∆∞·ªùi nh·∫•t l√† nh·ªØng ng∆∞·ªùi...  2021-09-30   \n2  3118086                                         L·∫°i l√† ƒêTC  2021-09-30   \n3  3118058  Ch√†o anh em, m√¨nh g·ª≠i anh ch·ªã em chi·∫øn l∆∞·ª£c ƒë√°...  2021-09-30   \n4  3118053            CTC v√†o 8.3 c√≥ d√≠nh b√¥ kh√¥ng m·ªçi ng∆∞·ªùi?  2021-09-30   \n\n   sentiment taggedSymbols  \n0        0.0       ['NKG']  \n1        0.0       ['ART']  \n2        0.0       ['DHA']  \n3        0.0            []  \n4        0.0       ['CTC']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>postID</th>\n      <th>originalContent</th>\n      <th>date</th>\n      <th>sentiment</th>\n      <th>taggedSymbols</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3118126</td>\n      <td>V√†o NKG ng√†y mai ·ªïn kh√¥ng c√°c b√°c? D√†i h·∫°n v√†o...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['NKG']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3118104</td>\n      <td>C√≥ m·ªôt ƒëi·ªÅu th·∫•y bu·ªìn c∆∞·ªùi nh·∫•t l√† nh·ªØng ng∆∞·ªùi...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['ART']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3118086</td>\n      <td>L·∫°i l√† ƒêTC</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['DHA']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3118058</td>\n      <td>Ch√†o anh em, m√¨nh g·ª≠i anh ch·ªã em chi·∫øn l∆∞·ª£c ƒë√°...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3118053</td>\n      <td>CTC v√†o 8.3 c√≥ d√≠nh b√¥ kh√¥ng m·ªçi ng∆∞·ªùi?</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['CTC']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"## Keep posts with negative and positive sentiment only","metadata":{}},{"cell_type":"code","source":"sentiment_df = df[df['sentiment'].isin([-1, 1])]\nsentiment_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:43.235440Z","iopub.execute_input":"2025-11-13T09:33:43.235796Z","iopub.status.idle":"2025-11-13T09:33:43.348410Z","shell.execute_reply.started":"2025-11-13T09:33:43.235775Z","shell.execute_reply":"2025-11-13T09:33:43.347636Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"     postID                                    originalContent        date  \\\n11  3117847  N√äN MUA G√å CHO B√ÅO C√ÅO QU√ù 3?\\n\\nTh√°ng 10 l√† g...  2021-09-30   \n29  3117591  D·ª± √°n Akari City v·ªõi quy m√¥ 5.000 cƒÉn h·ªô n·∫±m t...  2021-09-30   \n31  3117571  PNJ - H√ÄNH TR√åNH M·ªöI üî•üî•\\n\\nPNJ + 5,79% üî•\\n\\nT·∫°...  2021-09-30   \n48  3117327  Ti·∫øc qu√° kh√¥ng CE\\nNay ƒÉn ƒë∆∞·ª£c PNJ em vui qu√° ...  2021-09-30   \n56  3117230  Gi√° kh√≠ ƒë·ªët l·∫°i tƒÉng d·ª±ng ƒë·ª©ng mai l·∫°i tr·∫ßn ti...  2021-09-30   \n\n    sentiment                                      taggedSymbols  \n11        1.0  ['DCM', 'DPM', 'GMD', 'HPG', 'KSB', 'NTL', 'PV...  \n29        1.0                                            ['NLG']  \n31        1.0                       ['MSN', 'MWG', 'PC1', 'PNJ']  \n48        1.0                                            ['PNJ']  \n56        1.0                                            ['ASP']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>postID</th>\n      <th>originalContent</th>\n      <th>date</th>\n      <th>sentiment</th>\n      <th>taggedSymbols</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>3117847</td>\n      <td>N√äN MUA G√å CHO B√ÅO C√ÅO QU√ù 3?\\n\\nTh√°ng 10 l√† g...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['DCM', 'DPM', 'GMD', 'HPG', 'KSB', 'NTL', 'PV...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3117591</td>\n      <td>D·ª± √°n Akari City v·ªõi quy m√¥ 5.000 cƒÉn h·ªô n·∫±m t...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['NLG']</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>3117571</td>\n      <td>PNJ - H√ÄNH TR√åNH M·ªöI üî•üî•\\n\\nPNJ + 5,79% üî•\\n\\nT·∫°...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['MSN', 'MWG', 'PC1', 'PNJ']</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>3117327</td>\n      <td>Ti·∫øc qu√° kh√¥ng CE\\nNay ƒÉn ƒë∆∞·ª£c PNJ em vui qu√° ...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['PNJ']</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>3117230</td>\n      <td>Gi√° kh√≠ ƒë·ªët l·∫°i tƒÉng d·ª±ng ƒë·ª©ng mai l·∫°i tr·∫ßn ti...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['ASP']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"markdown","source":"## Data Cleaning","metadata":{}},{"cell_type":"code","source":"import re\n\ndef remove_links(text):\n    # X√≥a link d·∫°ng http(s)://... ho·∫∑c www....\n    text = re.sub(r\"http\\S+\", \"\", text)     # remove http:// ho·∫∑c https://\n    text = re.sub(r\"www\\.\\S+\", \"\", text)    # remove www...\n    text = re.sub(r\"\\S+\\.com\\S*\", \"\", text) # remove .com/.net/.vn...\n    return text.strip()\n\ndef clean_text(text):\n    text = str(text).lower()                          # lowercase\n    text = re.sub(r\"\\n+\", \". \", text)                # replace new line with period\n    text = remove_links(text)                         # remove links\n    text = re.sub(r\"@\\w+\", \"\", text)                  # remove mentions (@abc)\n    text = re.sub(r\"#\\w+\", \"\", text)                  # remove hashtags\n    text = re.sub(\n        r\"[^0-9a-zA-Z√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá\"\n        r\"√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±\"\n        r\"√Ω·ª≥·ª∑·ªπ·ªµƒë\\s!?,.]+\", \n        \" \", \n        text\n    )            # keep only letters, numbers and some punctuation\n    text = re.sub(r\"\\s+\", \" \", text).strip()          # remove extra spaces\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:43.349144Z","iopub.execute_input":"2025-11-13T09:33:43.349366Z","iopub.status.idle":"2025-11-13T09:33:43.355208Z","shell.execute_reply.started":"2025-11-13T09:33:43.349350Z","shell.execute_reply":"2025-11-13T09:33:43.354391Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"### Remove links in posts content","metadata":{}},{"cell_type":"code","source":"sentiment_df['originalContent'] = sentiment_df['originalContent'].apply(clean_text)\nsentiment_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:43.357094Z","iopub.execute_input":"2025-11-13T09:33:43.357741Z","iopub.status.idle":"2025-11-13T09:33:47.224439Z","shell.execute_reply.started":"2025-11-13T09:33:43.357718Z","shell.execute_reply":"2025-11-13T09:33:47.223534Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_191/952562065.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  sentiment_df['originalContent'] = sentiment_df['originalContent'].apply(clean_text)\n","output_type":"stream"},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"     postID                                    originalContent        date  \\\n11  3117847  n√™n mua g√¨ cho b√°o c√°o qu√Ω 3?. th√°ng 10 l√† gia...  2021-09-30   \n29  3117591  d·ª± √°n akari city v·ªõi quy m√¥ 5.000 cƒÉn h·ªô n·∫±m t...  2021-09-30   \n31  3117571  pnj h√†nh tr√¨nh m·ªõi . pnj 5,79 . t·∫°i sao n√≥i h√†...  2021-09-30   \n48  3117327  ti·∫øc qu√° kh√¥ng ce. nay ƒÉn ƒë∆∞·ª£c pnj em vui qu√° ...  2021-09-30   \n56  3117230  gi√° kh√≠ ƒë·ªët l·∫°i tƒÉng d·ª±ng ƒë·ª©ng mai l·∫°i tr·∫ßn ti...  2021-09-30   \n\n    sentiment                                      taggedSymbols  \n11        1.0  ['DCM', 'DPM', 'GMD', 'HPG', 'KSB', 'NTL', 'PV...  \n29        1.0                                            ['NLG']  \n31        1.0                       ['MSN', 'MWG', 'PC1', 'PNJ']  \n48        1.0                                            ['PNJ']  \n56        1.0                                            ['ASP']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>postID</th>\n      <th>originalContent</th>\n      <th>date</th>\n      <th>sentiment</th>\n      <th>taggedSymbols</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>3117847</td>\n      <td>n√™n mua g√¨ cho b√°o c√°o qu√Ω 3?. th√°ng 10 l√† gia...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['DCM', 'DPM', 'GMD', 'HPG', 'KSB', 'NTL', 'PV...</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>3117591</td>\n      <td>d·ª± √°n akari city v·ªõi quy m√¥ 5.000 cƒÉn h·ªô n·∫±m t...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['NLG']</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>3117571</td>\n      <td>pnj h√†nh tr√¨nh m·ªõi . pnj 5,79 . t·∫°i sao n√≥i h√†...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['MSN', 'MWG', 'PC1', 'PNJ']</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>3117327</td>\n      <td>ti·∫øc qu√° kh√¥ng ce. nay ƒÉn ƒë∆∞·ª£c pnj em vui qu√° ...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['PNJ']</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>3117230</td>\n      <td>gi√° kh√≠ ƒë·ªët l·∫°i tƒÉng d·ª±ng ƒë·ª©ng mai l·∫°i tr·∫ßn ti...</td>\n      <td>2021-09-30</td>\n      <td>1.0</td>\n      <td>['ASP']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer \nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset, DataLoader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.225681Z","iopub.execute_input":"2025-11-13T09:33:47.225893Z","iopub.status.idle":"2025-11-13T09:33:47.230104Z","shell.execute_reply.started":"2025-11-13T09:33:47.225875Z","shell.execute_reply":"2025-11-13T09:33:47.229375Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"import torch\nclass SentimentDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=100, mode=\"train\",test_size=0.2, random_state=42):\n        # keep only necessary columns\n        df = df[['originalContent', 'sentiment']]\n        \n        # train/test split\n        train_df, test_df = train_test_split(\n            df, \n            test_size=test_size,\n            stratify=df['sentiment'],\n            random_state=random_state\n        )\n        \n        self.df = train_df if mode == \"train\" else test_df \n        \n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        text = row['originalContent']\n        label = 1 if row['sentiment'] == 1 else 0\n        \n        tokens = self.tokenizer(\n            text, \n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        \n        return {\n            \"input_ids\": tokens['input_ids'].squeeze(0),\n            \"attention_mask\": tokens['attention_mask'].squeeze(0),\n            \"labels\": torch.tensor(label, dtype=torch.long)\n            }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.230952Z","iopub.execute_input":"2025-11-13T09:33:47.231156Z","iopub.status.idle":"2025-11-13T09:33:47.242637Z","shell.execute_reply.started":"2025-11-13T09:33:47.231141Z","shell.execute_reply":"2025-11-13T09:33:47.241801Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"from torch.utils.data import WeightedRandomSampler\n# load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"5CD-AI/Vietnamese-Sentiment-visobert\")\n\n# Create dataset\ntrain_dataset = SentimentDataset(sentiment_df, tokenizer, mode='train')\ntest_dataset = SentimentDataset(sentiment_df, tokenizer, mode='test')\n\n# compute class weights\nlabels = train_dataset.df['sentiment'].map({-1:0, 1:1}).values\nclass_counts = [sum(labels==0), sum(labels==1)] # [neg_count, pos_count]\nclass_weights = [1.0 / count for count in class_counts]\n\n# assign weight to each sample\nsample_weights = [class_weights[label] for label in labels]\n\n# create WeightedRandomSampler\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),\n    replacement=True # allow sampling the same example multiple times\n)\n\n# create DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# check a batch\nbatch = next(iter(train_loader))\nprint(batch['input_ids'].shape)  # (batch_size, seq_len)\nprint(batch['labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.243691Z","iopub.execute_input":"2025-11-13T09:33:47.243882Z","iopub.status.idle":"2025-11-13T09:33:47.586297Z","shell.execute_reply.started":"2025-11-13T09:33:47.243867Z","shell.execute_reply":"2025-11-13T09:33:47.585409Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 100])\ntensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n        0, 0, 1, 0, 1, 1, 1, 1])\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# check a batch\nbatch = next(iter(train_loader))\nprint(batch['input_ids'].shape)  # (batch_size, seq_len)\nprint(batch['labels'])\nprint(batch['labels'].bincount()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.587118Z","iopub.execute_input":"2025-11-13T09:33:47.587445Z","iopub.status.idle":"2025-11-13T09:33:47.627485Z","shell.execute_reply.started":"2025-11-13T09:33:47.587413Z","shell.execute_reply":"2025-11-13T09:33:47.626769Z"}},"outputs":[{"name":"stdout","text":"torch.Size([32, 100])\ntensor([1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n        0, 1, 1, 1, 0, 0, 1, 1])\ntensor([13, 19])\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"## Load pretrained model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers.models.xlm_roberta.modeling_xlm_roberta import XLMRobertaClassificationHead\nfrom transformers import AutoModelForSequenceClassification, AutoConfig\nmodel_name = \"5CD-AI/Vietnamese-Sentiment-visobert\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n\n# 1. Load config\nconfig = AutoConfig.from_pretrained(\"5CD-AI/Vietnamese-Sentiment-visobert\")\nconfig.num_labels = 2  # important\n\n# 2. Load model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    config=config,\n    ignore_mismatched_sizes=True   # avoid shape errors\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.628159Z","iopub.execute_input":"2025-11-13T09:33:47.628617Z","iopub.status.idle":"2025-11-13T09:33:47.964057Z","shell.execute_reply.started":"2025-11-13T09:33:47.628598Z","shell.execute_reply":"2025-11-13T09:33:47.963368Z"}},"outputs":[{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at 5CD-AI/Vietnamese-Sentiment-visobert and are newly initialized because the shapes did not match:\n- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n- classifier.out_proj.weight: found shape torch.Size([3, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"def freeze_model_layers(model, unfreeze_last_n=4):\n    \"\"\"\n    Freeze all but the last `n` transformer layers of the encoder,\n    plus keep the classifier trainable.\n    \"\"\"\n    # 1. Freeze embeddings\n    for param in model.roberta.embeddings.parameters():\n        param.requires_grad = False\n\n    # 2. Freeze all encoder layers except the last `unfreeze_last_n`\n    for i, layer in enumerate(model.roberta.encoder.layer):\n        if i < len(model.roberta.encoder.layer) - unfreeze_last_n:\n            for param in layer.parameters():\n                param.requires_grad = False\n        else:\n            for param in layer.parameters():\n                param.requires_grad = True\n\n    # 3. Always train classifier head\n    for param in model.classifier.parameters():\n        param.requires_grad = True\n\n    # Print summary\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    print(f\"Trainable params: {trainable_params/1e6:.2f}M / {total_params/1e6:.2f}M total \"\n          f\"({100 * trainable_params/total_params:.1f}%)\")\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.966408Z","iopub.execute_input":"2025-11-13T09:33:47.966984Z","iopub.status.idle":"2025-11-13T09:33:47.972499Z","shell.execute_reply.started":"2025-11-13T09:33:47.966961Z","shell.execute_reply":"2025-11-13T09:33:47.971650Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"freeze_model_layers(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.973073Z","iopub.execute_input":"2025-11-13T09:33:47.973285Z","iopub.status.idle":"2025-11-13T09:33:47.992495Z","shell.execute_reply.started":"2025-11-13T09:33:47.973262Z","shell.execute_reply":"2025-11-13T09:33:47.991657Z"}},"outputs":[{"name":"stdout","text":"Trainable params: 28.94M / 97.57M total (29.7%)\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"XLMRobertaForSequenceClassification(\n  (roberta): XLMRobertaModel(\n    (embeddings): XLMRobertaEmbeddings(\n      (word_embeddings): Embedding(15004, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): XLMRobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x XLMRobertaLayer(\n          (attention): XLMRobertaAttention(\n            (self): XLMRobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): XLMRobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): XLMRobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): XLMRobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): XLMRobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.amp import autocast, GradScaler\nfrom torch.nn.utils import clip_grad_norm_\nfrom transformers import (\n    AutoTokenizer, \n    AutoModelForSequenceClassification,\n    get_linear_schedule_with_warmup\n)\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n# Evaluation function\ndef evaluate_model(model, data_loader, device='cuda'):\n    model.eval()\n    preds, true_labels = [], []\n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\", leave=False):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            with autocast('cuda'):  # Add this for mixed precision\n                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits \n            \n            batch_preds = torch.argmax(logits, dim=1)\n            preds.extend(batch_preds.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n            \n    acc = accuracy_score(true_labels, preds)\n    f1 = f1_score(true_labels, preds)\n    precision = precision_score(true_labels, preds)\n    recall = recall_score(true_labels, preds)\n\n    print(f\"Eval | Acc: {acc:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n    return acc, f1, precision, recall\n\ndef train_model(model, train_loader, val_loader=None,\n                epochs=3, lr=2e-5, weight_decay=0.01,\n                warmup_ratio=0.1, max_grad_norm=1.0, device='cuda',\n                save_dir=\"./checkpoints\", save_every_n_epochs=2):\n    \n    os.makedirs(save_dir, exist_ok=True)\n    model.to(device)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    \n    total_steps = len(train_loader) * epochs\n    warmup_steps = int(total_steps * warmup_ratio)\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=warmup_steps,\n        num_training_steps=total_steps\n    )\n    \n    scaler = GradScaler()\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0.0\n        \n        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            optimizer.zero_grad()\n            \n            with autocast(device_type='cuda'):\n                outputs = model(input_ids=input_ids,\n                                attention_mask=attention_mask,\n                                labels=labels)\n                loss = outputs.loss\n                \n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            clip_grad_norm_(model.parameters(), max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n            \n            total_loss += loss.item()\n        \n        avg_loss = total_loss / len(train_loader)\n        print(f\"Epoch {epoch+1} | Train loss: {avg_loss:.4f}\")\n        \n        # Evaluate\n        if val_loader is not None:\n            evaluate_model(model, val_loader, device=device)\n        \n        # === SAVE EVERY `save_every_n_epochs` EPOCHS ===\n        if (epoch + 1) % save_every_n_epochs == 0:\n            save_path = os.path.join(save_dir, f\"model_epoch_{epoch+1}\")\n            model.save_pretrained(save_path)\n            tokenizer.save_pretrained(save_path)\n            print(f\"Checkpoint saved: {save_path}\")\n\n    # Save final model\n    final_path = os.path.join(save_dir, \"model_final\")\n    model.save_pretrained(final_path)\n    tokenizer.save_pretrained(final_path)\n    print(f\"Final model saved: {final_path}\")\n    \n    print(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:47.993330Z","iopub.execute_input":"2025-11-13T09:33:47.993580Z","iopub.status.idle":"2025-11-13T09:33:48.006891Z","shell.execute_reply.started":"2025-11-13T09:33:47.993557Z","shell.execute_reply":"2025-11-13T09:33:48.006022Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"train_model(model, train_loader, val_loader=test_loader, epochs=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T09:33:48.007743Z","iopub.execute_input":"2025-11-13T09:33:48.008011Z","iopub.status.idle":"2025-11-13T10:31:33.582814Z","shell.execute_reply.started":"2025-11-13T09:33:48.007988Z","shell.execute_reply":"2025-11-13T10:31:33.581919Z"}},"outputs":[{"name":"stderr","text":"Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:05<00:00, 10.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train loss: 0.5141\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.7735 | F1: 0.8329 | Precision: 0.9295 | Recall: 0.7545\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:05<00:00, 10.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train loss: 0.4010\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 256}\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8148 | F1: 0.8692 | Precision: 0.9211 | Recall: 0.8229\nCheckpoint saved: ./checkpoints/model_epoch_2\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 11.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train loss: 0.3365\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8263 | F1: 0.8787 | Precision: 0.9197 | Recall: 0.8412\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:03<00:00, 11.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train loss: 0.2870\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 256}\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8185 | F1: 0.8714 | Precision: 0.9269 | Recall: 0.8222\nCheckpoint saved: ./checkpoints/model_epoch_4\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 10.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train loss: 0.2483\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8194 | F1: 0.8722 | Precision: 0.9264 | Recall: 0.8240\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 11.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train loss: 0.2141\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 256}\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8246 | F1: 0.8771 | Precision: 0.9219 | Recall: 0.8364\nCheckpoint saved: ./checkpoints/model_epoch_6\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 11.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train loss: 0.1858\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8377 | F1: 0.8888 | Precision: 0.9119 | Recall: 0.8668\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 10.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train loss: 0.1638\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 256}\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8331 | F1: 0.8842 | Precision: 0.9192 | Recall: 0.8518\nCheckpoint saved: ./checkpoints/model_epoch_8\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 10.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train loss: 0.1537\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8413 | F1: 0.8916 | Precision: 0.9114 | Recall: 0.8727\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3347/3347 [05:04<00:00, 11.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train loss: 0.1415\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:407: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\nNon-default generation parameters: {'max_length': 256}\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Eval | Acc: 0.8395 | F1: 0.8900 | Precision: 0.9132 | Recall: 0.8680\nCheckpoint saved: ./checkpoints/model_epoch_10\nFinal model saved: ./checkpoints/model_final\nTraining complete!\n","output_type":"stream"}],"execution_count":61},{"cell_type":"markdown","source":"## Apply the Model for Neutral Sentiment Posts","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.amp import autocast\nfrom tqdm import tqdm\n\n@torch.no_grad()\ndef analyze_zero_sentiment_posts(\n    df,\n    model,\n    tokenizer,\n    text_column='originalContent',\n    sentiment_column='sentiment',\n    batch_size=64,\n    device='cuda',\n    label_map={0: -1, 1: 1}  # 0 in logits ‚Üí negative, 1 ‚Üí positive\n):\n    \"\"\"\n    Predict sentiment for rows where `sentiment == 0` (unknown/neutral) efficiently\n    for large datasets.\n\n    Args:\n        df (pd.DataFrame): Input dataframe\n        model: Trained HuggingFace model\n        tokenizer: Corresponding tokenizer\n        text_column: Name of column with text\n        sentiment_column: Name of column with labels (0, 1, -1)\n        batch_size: Inference batch size\n        device: 'cuda' or 'cpu'\n        label_map: Map from model output logits ‚Üí sentiment label\n\n    Returns:\n        df_with_pred: DataFrame with new column `predicted_sentiment`\n    \"\"\"\n\n    # Filter rows with sentiment == 0\n    zero_df = df[df[sentiment_column] == 0].copy()\n    if zero_df.empty:\n        print(\"No rows with sentiment == 0 found.\")\n        df['predicted_sentiment'] = None\n        return df\n\n    print(f\"Analyzing {len(zero_df)} posts with sentiment == 0...\")\n\n    model.eval()\n    model.to(device)\n\n    # Clean text column efficiently\n    zero_df[text_column] = [clean_text(str(t)) for t in zero_df[text_column].fillna(\"\")]\n\n    pred_labels = []\n\n    # Batch inference\n    for start_idx in tqdm(range(0, len(zero_df), batch_size), desc=\"Predicting\"):\n        batch_texts = zero_df[text_column].iloc[start_idx:start_idx+batch_size].tolist()\n        \n        encodings = tokenizer(\n            batch_texts,\n            truncation=True,\n            padding=True,\n            max_length=256,\n            return_tensors='pt'\n        )\n\n        input_ids = encodings['input_ids'].to(device)\n        attention_mask = encodings['attention_mask'].to(device)\n\n        with autocast(device_type='cuda' if 'cuda' in device else 'cpu'):\n            logits = model(input_ids=input_ids, attention_mask=attention_mask).logits\n            preds = torch.argmax(logits, dim=-1)\n\n        pred_labels.extend([label_map[int(p)] for p in preds.cpu()])\n\n        # Free GPU memory after each batch\n        del input_ids, attention_mask, logits, preds\n        torch.cuda.empty_cache()\n\n    # Assign predictions directly to original df\n    df_with_pred = df.copy()\n    df_with_pred['predicted_sentiment'] = None\n    df_with_pred.loc[df[sentiment_column] == 0, 'predicted_sentiment'] = pred_labels\n\n    # Summary\n    pos = sum(p == 1 for p in pred_labels)\n    neg = sum(p == -1 for p in pred_labels)\n    print(f\"\\nResults for sentiment == 0 posts:\")\n    print(f\"  Positive: {pos} ({pos/len(pred_labels)*100:.1f}%)\")\n    print(f\"  Negative: {neg} ({neg/len(pred_labels)*100:.1f}%)\")\n\n    return df_with_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:31:33.585469Z","iopub.execute_input":"2025-11-13T10:31:33.585675Z","iopub.status.idle":"2025-11-13T10:31:33.595547Z","shell.execute_reply.started":"2025-11-13T10:31:33.585659Z","shell.execute_reply":"2025-11-13T10:31:33.594673Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"new_df = pd.read_csv('/kaggle/input/all-posts/all_posts.csv')\nnew_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T10:31:33.596261Z","iopub.execute_input":"2025-11-13T10:31:33.596479Z","iopub.status.idle":"2025-11-13T10:31:59.017851Z","shell.execute_reply.started":"2025-11-13T10:31:33.596463Z","shell.execute_reply":"2025-11-13T10:31:59.017138Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"    postID                                    originalContent        date  \\\n0  3118126  V√†o NKG ng√†y mai ·ªïn kh√¥ng c√°c b√°c? D√†i h·∫°n v√†o...  2021-09-30   \n1  3118104  C√≥ m·ªôt ƒëi·ªÅu th·∫•y bu·ªìn c∆∞·ªùi nh·∫•t l√† nh·ªØng ng∆∞·ªùi...  2021-09-30   \n2  3118086                                         L·∫°i l√† ƒêTC  2021-09-30   \n3  3118058  Ch√†o anh em, m√¨nh g·ª≠i anh ch·ªã em chi·∫øn l∆∞·ª£c ƒë√°...  2021-09-30   \n4  3118053            CTC v√†o 8.3 c√≥ d√≠nh b√¥ kh√¥ng m·ªçi ng∆∞·ªùi?  2021-09-30   \n\n   sentiment taggedSymbols  \n0        0.0       ['NKG']  \n1        0.0       ['ART']  \n2        0.0       ['DHA']  \n3        0.0            []  \n4        0.0       ['CTC']  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>postID</th>\n      <th>originalContent</th>\n      <th>date</th>\n      <th>sentiment</th>\n      <th>taggedSymbols</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3118126</td>\n      <td>V√†o NKG ng√†y mai ·ªïn kh√¥ng c√°c b√°c? D√†i h·∫°n v√†o...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['NKG']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3118104</td>\n      <td>C√≥ m·ªôt ƒëi·ªÅu th·∫•y bu·ªìn c∆∞·ªùi nh·∫•t l√† nh·ªØng ng∆∞·ªùi...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['ART']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3118086</td>\n      <td>L·∫°i l√† ƒêTC</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['DHA']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3118058</td>\n      <td>Ch√†o anh em, m√¨nh g·ª≠i anh ch·ªã em chi·∫øn l∆∞·ª£c ƒë√°...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3118053</td>\n      <td>CTC v√†o 8.3 c√≥ d√≠nh b√¥ kh√¥ng m·ªçi ng∆∞·ªùi?</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['CTC']</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"new_df = analyze_zero_sentiment_posts(\n    df=new_df,           # original dataframe\n    model=model,               # trained model\n    tokenizer=tokenizer,       # same tokenizer\n    text_column='originalContent',\n    sentiment_column='sentiment',\n    batch_size=32,\n    device='cuda'\n)\n\nnew_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T13:16:41.825228Z","iopub.execute_input":"2025-11-13T13:16:41.826007Z","iopub.status.idle":"2025-11-13T15:59:46.361684Z","shell.execute_reply.started":"2025-11-13T13:16:41.825974Z","shell.execute_reply":"2025-11-13T15:59:46.360741Z"}},"outputs":[{"name":"stdout","text":"Analyzing 5709889 posts with sentiment == 0...\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 178435/178435 [2:40:54<00:00, 18.48it/s]  \n","output_type":"stream"},{"name":"stdout","text":"\nResults for sentiment == 0 posts:\n  Positive: 3394107 (59.4%)\n  Negative: 2315782 (40.6%)\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"    postID                                    originalContent        date  \\\n0  3118126  V√†o NKG ng√†y mai ·ªïn kh√¥ng c√°c b√°c? D√†i h·∫°n v√†o...  2021-09-30   \n1  3118104  C√≥ m·ªôt ƒëi·ªÅu th·∫•y bu·ªìn c∆∞·ªùi nh·∫•t l√† nh·ªØng ng∆∞·ªùi...  2021-09-30   \n2  3118086                                         L·∫°i l√† ƒêTC  2021-09-30   \n3  3118058  Ch√†o anh em, m√¨nh g·ª≠i anh ch·ªã em chi·∫øn l∆∞·ª£c ƒë√°...  2021-09-30   \n4  3118053            CTC v√†o 8.3 c√≥ d√≠nh b√¥ kh√¥ng m·ªçi ng∆∞·ªùi?  2021-09-30   \n\n   sentiment taggedSymbols predicted_sentiment  \n0        0.0       ['NKG']                   1  \n1        0.0       ['ART']                  -1  \n2        0.0       ['DHA']                   1  \n3        0.0            []                   1  \n4        0.0       ['CTC']                   1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>postID</th>\n      <th>originalContent</th>\n      <th>date</th>\n      <th>sentiment</th>\n      <th>taggedSymbols</th>\n      <th>predicted_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3118126</td>\n      <td>V√†o NKG ng√†y mai ·ªïn kh√¥ng c√°c b√°c? D√†i h·∫°n v√†o...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['NKG']</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3118104</td>\n      <td>C√≥ m·ªôt ƒëi·ªÅu th·∫•y bu·ªìn c∆∞·ªùi nh·∫•t l√† nh·ªØng ng∆∞·ªùi...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['ART']</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3118086</td>\n      <td>L·∫°i l√† ƒêTC</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['DHA']</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3118058</td>\n      <td>Ch√†o anh em, m√¨nh g·ª≠i anh ch·ªã em chi·∫øn l∆∞·ª£c ƒë√°...</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>[]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3118053</td>\n      <td>CTC v√†o 8.3 c√≥ d√≠nh b√¥ kh√¥ng m·ªçi ng∆∞·ªùi?</td>\n      <td>2021-09-30</td>\n      <td>0.0</td>\n      <td>['CTC']</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"output_path = '/kaggle/working/posts_sentiment.csv'\nnew_df.to_csv(output_path, index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T15:59:52.964311Z","iopub.execute_input":"2025-11-13T15:59:52.964875Z","iopub.status.idle":"2025-11-13T16:00:29.202343Z","shell.execute_reply.started":"2025-11-13T15:59:52.964848Z","shell.execute_reply":"2025-11-13T16:00:29.201727Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"from IPython.display import FileLink\n\nFileLink(\"/kaggle/working/posts_sentiment.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T16:01:20.452932Z","iopub.execute_input":"2025-11-13T16:01:20.453652Z","iopub.status.idle":"2025-11-13T16:01:20.458222Z","shell.execute_reply.started":"2025-11-13T16:01:20.453624Z","shell.execute_reply":"2025-11-13T16:01:20.457659Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/posts_sentiment.csv","text/html":"<a href='/kaggle/working/posts_sentiment.csv' target='_blank'>/kaggle/working/posts_sentiment.csv</a><br>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"import shutil\n\n# Zip the file\nshutil.make_archive(\"/kaggle/working/posts_sentiment\", \"zip\", root_dir=\"/kaggle/working\", base_dir=\"posts_sentiment.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T16:03:39.554713Z","iopub.execute_input":"2025-11-13T16:03:39.555029Z","iopub.status.idle":"2025-11-13T16:04:46.319833Z","shell.execute_reply.started":"2025-11-13T16:03:39.555007Z","shell.execute_reply":"2025-11-13T16:04:46.319132Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/posts_sentiment.zip'"},"metadata":{}}],"execution_count":70},{"cell_type":"code","source":"import shutil\n\n# Zip the final model folder\nshutil.make_archive(\"/kaggle/working/final_model\", \"zip\", \"/kaggle/working/checkpoints/model_final\")\n\n# Now Kaggle UI will show final_model.zip in the Output panel for download\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-13T16:05:37.722893Z","iopub.execute_input":"2025-11-13T16:05:37.723225Z","iopub.status.idle":"2025-11-13T16:05:56.854159Z","shell.execute_reply.started":"2025-11-13T16:05:37.723202Z","shell.execute_reply":"2025-11-13T16:05:56.853544Z"}},"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/final_model.zip'"},"metadata":{}}],"execution_count":71},{"cell_type":"markdown","source":"jhkjmbmg","metadata":{}}]}