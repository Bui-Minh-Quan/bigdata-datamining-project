{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3c0750",
   "metadata": {},
   "source": [
    "# T√≥m t·∫Øt tin t·ª©c t·ª´ all_news.csv\n",
    "\n",
    "Notebook n√†y s·ª≠ d·ª•ng **Google Gemini AI** v√† **TOON format** ƒë·ªÉ:\n",
    "- üì∞ T√≥m t·∫Øt tin t·ª©c t√†i ch√≠nh t·ª´ `all_news.csv`\n",
    "- üéØ T·ª± ƒë·ªông nh·∫≠n di·ªán m√£ c·ªï phi·∫øu\n",
    "- üí∞ **Ti·∫øt ki·ªám 30-60% token** nh·ªù TOON format\n",
    "- ‚ö° TƒÉng t·ªëc ƒë·ªô ph·∫£n h·ªìi v√† gi·∫£m chi ph√≠ API\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ ƒêi·ªÉm n·ªïi b·∫≠t\n",
    "\n",
    "‚ú® **TOON Format Integration** - ƒê·ªãnh d·∫°ng t·ªëi ∆∞u cho LLM, gi·∫£m token hi·ªáu qu·∫£  \n",
    "üîÑ **Retry Logic** - T·ª± ƒë·ªông th·ª≠ l·∫°i khi g·∫∑p l·ªói  \n",
    "üíæ **Checkpoint System** - L∆∞u ti·∫øn ƒë·ªô, ti·∫øp t·ª•c ƒë∆∞·ª£c khi b·ªã gi√°n ƒëo·∫°n  \n",
    "ü§ñ **Multi-model Strategy** - T·ª± ƒë·ªông chuy·ªÉn model khi c·∫ßn  \n",
    "üìä **Stock Code Detection** - Nh·∫≠n di·ªán th√¥ng minh m√£ c·ªï phi·∫øu t·ª´ n·ªôi dung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "253b7954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ kh·ªüi t·∫°o models v·ªõi 5 API key(s)\n",
      "ƒêang d√πng key: ...JIlHSfS4\n"
     ]
    }
   ],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# C·∫•u h√¨nh API Keys v·ªõi rotation support\n",
    "api_keys_str = os.getenv(\"GOOGLE_API_KEY\", \"\")\n",
    "GOOGLE_API_KEYS = [key.strip() for key in api_keys_str.split(\",\") if key.strip()]\n",
    "\n",
    "if not GOOGLE_API_KEYS:\n",
    "    raise ValueError(\"GOOGLE_API_KEY kh√¥ng ƒë∆∞·ª£c c·∫•u h√¨nh\")\n",
    "\n",
    "# Kh·ªüi t·∫°o v·ªõi key ƒë·∫ßu ti√™n\n",
    "current_key_index = 0\n",
    "current_api_key = GOOGLE_API_KEYS[current_key_index]\n",
    "genai.configure(api_key=current_api_key)\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\", temperature=0.02)\n",
    "model_more_temperature = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\", temperature=0.1)\n",
    "model_pro = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-exp-03-25\", temperature=0.1)\n",
    "\n",
    "print(f\"ƒê√£ kh·ªüi t·∫°o models v·ªõi {len(GOOGLE_API_KEYS)} API key(s)\")\n",
    "print(f\"ƒêang d√πng key: ...{current_api_key[-8:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf56c97",
   "metadata": {},
   "source": [
    "## üìã C·∫•u tr√∫c d·ªØ li·ªáu\n",
    "\n",
    "File `all_news.csv` c√≥ c√°c c·ªôt sau:\n",
    "- `postID`: ID b√†i vi·∫øt\n",
    "- `date`: Ng√†y xu·∫•t b·∫£n\n",
    "- `sentiment`: Ph√¢n t√≠ch c·∫£m x√∫c (n·∫øu c√≥)\n",
    "- `taggedSymbols`: Danh s√°ch m√£ c·ªï phi·∫øu ƒë∆∞·ª£c tag (d·∫°ng list)\n",
    "- `combinedContent`: N·ªôi dung b√†i b√°o ƒë·∫ßy ƒë·ªß (bao g·ªìm Title v√† Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fae51439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: ƒê·ªçc v√† ki·ªÉm tra d·ªØ li·ªáu\n",
    "def test_read_news():\n",
    "    \"\"\"\n",
    "    Ki·ªÉm tra xem c√≥ ƒë·ªçc ƒë∆∞·ª£c file all_news.csv kh√¥ng\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_test = pd.read_csv(\"all_news/all_news.csv\", nrows=3)\n",
    "        print(f\"‚úì ƒê·ªçc th√†nh c√¥ng file all_news.csv\")\n",
    "        print(f\"\\nüìä C√°c c·ªôt: {df_test.columns.tolist()}\")\n",
    "        print(f\"\\nüìù M·∫´u d·ªØ li·ªáu (3 d√≤ng ƒë·∫ßu):\")\n",
    "        print(df_test[['postID', 'date', 'taggedSymbols']].head())\n",
    "        \n",
    "        # Ki·ªÉm tra combinedContent\n",
    "        if len(df_test) > 0:\n",
    "            print(f\"\\nüìÑ M·∫´u combinedContent:\")\n",
    "            print(df_test.iloc[0]['combinedContent'][:200] + \"...\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi ƒë·ªçc file: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ch·∫°y test (b·ªè comment ƒë·ªÉ ki·ªÉm tra)\n",
    "# test_read_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "113d252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a prompt template t·ªëi ∆∞u v·ªõi TOON format\n",
    "news_summarize_with_stock_template = PromptTemplate.from_template(\"\"\"\n",
    "B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch th·ªã tr∆∞·ªùng ch·ª©ng kho√°n Vi·ªát Nam. \n",
    "\n",
    "D·ªØ li·ªáu ƒë·∫ßu v√†o c√≥ th·ªÉ ·ªü ƒë·ªãnh d·∫°ng TOON (Token-Oriented Object Notation) - m·ªôt format ti·∫øt ki·ªám token.\n",
    "N·∫øu th·∫•y ```toon block, d·ªØ li·ªáu s·∫Ω c√≥ d·∫°ng b·∫£ng v·ªõi c√°c tr∆∞·ªùng: id, taggedSymbols, title, content.\n",
    "\n",
    "Nhi·ªám v·ª• c·ªßa b·∫°n:\n",
    "1. ƒê·ªçc v√† hi·ªÉu d·ªØ li·ªáu t·ª´ format TOON ho·∫∑c text th√¥ng th∆∞·ªùng\n",
    "2. T√≥m t·∫Øt t·ª´ng tin t·ª©c m·ªôt c√°ch ng·∫Øn g·ªçn, s√∫c t√≠ch\n",
    "3. QUAN TR·ªåNG NH·∫§T: X√°c ƒë·ªãnh ch√≠nh x√°c M√É C·ªî PHI·∫æU li√™n quan\n",
    "\n",
    "Quy t·∫Øc nh·∫≠n di·ªán m√£ c·ªï phi·∫øu:\n",
    "1. ∆Øu ti√™n s·ª≠ d·ª•ng m√£ t·ª´ taggedSymbols n·∫øu c√≥ v√† ch√≠nh x√°c\n",
    "2. N·∫øu taggedSymbols tr·ªëng/sai, T·ª∞ NH·∫¨N DI·ªÜN t·ª´ n·ªôi dung:\n",
    "   - T√¨m T√äN C√îNG TY (VD: FPT, Vietcombank, Vingroup, H√≤a Ph√°t...)\n",
    "   - Chuy·ªÉn th√†nh M√É CH·ª®NG KHO√ÅN ch√≠nh x√°c (FPT‚ÜíFPT, Vietcombank‚ÜíVCB, Vingroup‚ÜíVIC, H√≤a Ph√°t‚ÜíHPG)\n",
    "   - Nhi·ªÅu c√¥ng ty ‚Üí li·ªát k√™ T·∫§T C·∫¢ m√£, c√°ch nhau b·ªüi d·∫•u ph·∫©y\n",
    "3. Ch·ªâ n√≥i ng√†nh/lƒ©nh v·ª±c chung ‚Üí ƒë·ªÉ tr·ªëng m√£\n",
    "4. M√É ph·∫£i vi·∫øt HOA v√† ch√≠nh x√°c theo HOSE/HNX/UPCOM\n",
    "\n",
    "Danh s√°ch c√¥ng ty ph·ªï bi·∫øn:\n",
    "FPT‚ÜíFPT | Vietcombank‚ÜíVCB | Vingroup/Vinhomes‚ÜíVIC,VHM | H√≤a Ph√°t‚ÜíHPG | PV Gas‚ÜíGAS\n",
    "Masan‚ÜíMSN,MCH | Mobile World‚ÜíMWG | SSI‚ÜíSSI | Viettel‚ÜíVTP,CTR,VGI | Sabeco‚ÜíSAB\n",
    "Vinamilk‚ÜíVNM | Techcombank‚ÜíTCB | BIDV‚ÜíBID | VietinBank‚ÜíCTG | VPBank‚ÜíVPB\n",
    "\n",
    "D·ªØ li·ªáu ƒë·∫ßu v√†o:\n",
    "{articles_list}\n",
    "\n",
    "Format ƒë·∫ßu ra (M·ªñI TIN M·ªòT D√íNG):\n",
    "[M√É ho·∫∑c tr·ªëng]: [Ti√™u ƒë·ªÅ ng·∫Øn] | [T√≥m t·∫Øt chi ti·∫øt v·ªõi s·ªë li·ªáu]\n",
    "\n",
    "V√≠ d·ª•:\n",
    "FPT: FPT mua l·∫°i 5 tri·ªáu c·ªï phi·∫øu qu·ªπ | FPT Corporation mua t·ªëi ƒëa 5 tri·ªáu cp qu·ªπ Q1/2025, gi√° ~120K ƒë·ªìng/cp, t·ªïng 600 t·ª∑ ƒë·ªìng, t·ªëi ∆∞u v·ªën.\n",
    "VCB: Vietcombank l√£i Q4 tƒÉng 18% | VCB l·ª£i nhu·∫≠n Q4/2024 ƒë·∫°t 9.200 t·ª∑ (+18% YoY), t√≠n d·ª•ng +15%, d·ªãch v·ª• +22%.\n",
    "HPG, VHM: Th√©p v√† BƒêS h∆∞·ªüng l·ª£i g√≥i 120K t·ª∑ | G√≥i k√≠ch c·∫ßu 120K t·ª∑ t·∫≠p trung h·∫° t·∫ßng, nh√† XH; HPG nhu c·∫ßu th√©p +12%, VHM d·ª± √°n +30%.\n",
    ": VN-Index tƒÉng nh·ªù d√≤ng ti·ªÅn ngo·∫°i | VN-Index +8.5 ƒëi·ªÉm l√™n 1.245, thanh kho·∫£n 18.5K t·ª∑, ngo·∫°i mua r√≤ng 450 t·ª∑.\n",
    "\n",
    "L∆∞u √Ω:\n",
    "- M·ªói tin M·ªòT D√íNG, kh√¥ng xu·ªëng d√≤ng\n",
    "- Kh√¥ng d√πng \":\" trong n·ªôi dung t√≥m t·∫Øt\n",
    "- GHI R√ï s·ªë li·ªáu (%, s·ªë ti·ªÅn, s·ªë l∆∞·ª£ng...)\n",
    "- Nhi·ªÅu m√£ ‚Üí ghi h·∫øt, c√°ch b·∫±ng d·∫•u ph·∫©y\n",
    "- Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c m√£ ‚Üí ƒë·ªÉ tr·ªëng\n",
    "- T·ªïng 20 tin quan tr·ªçng nh·∫•t\n",
    "- ∆Øu ti√™n tin ·∫£nh h∆∞·ªüng l·ªõn\n",
    "\n",
    "T√≥m t·∫Øt:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d7de0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ kh·ªüi t·∫°o chains\n"
     ]
    }
   ],
   "source": [
    "chain_summary = news_summarize_with_stock_template | model\n",
    "chain_summary_more_temp = news_summarize_with_stock_template | model_more_temperature\n",
    "chain_summary_pro = news_summarize_with_stock_template | model_pro\n",
    "\n",
    "print(\"ƒê√£ kh·ªüi t·∫°o chains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c188354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOON format ƒë√£ s·∫µn\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import importlib.util\n",
    "    if importlib.util.find_spec(\"toon_format\") is None:\n",
    "        print(\"ƒêang c√†i ƒë·∫∑t TOON format...\")\n",
    "        subprocess.check_call([\"pip\", \"install\", \"toon-format\"], stdout=subprocess.DEVNULL)\n",
    "        print(\"ƒê√£ c√†i ƒë·∫∑t TOON format\")\n",
    "    else:\n",
    "        print(\"TOON format ƒë√£ s·∫µn\")\n",
    "except Exception as e:\n",
    "    print(f\"Kh√¥ng th·ªÉ c√†i ƒë·∫∑t TOON: {e}\")\n",
    "    print(\"S·∫Ω d√πng JSON th√¥ng th∆∞·ªùng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe8c78",
   "metadata": {},
   "source": [
    "### üí° V·ªÅ TOON Format\n",
    "\n",
    "**TOON (Token-Oriented Object Notation)** l√† format ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·∫∑c bi·ªát cho LLM:\n",
    "\n",
    "- ‚úÖ **Ti·∫øt ki·ªám 30-60% token** so v·ªõi JSON cho d·ªØ li·ªáu d·∫°ng b·∫£ng\n",
    "- ‚úÖ **D·ªÖ ƒë·ªçc** h∆°n JSON, t∆∞∆°ng t·ª± YAML\n",
    "- ‚úÖ **LLM hi·ªÉu t·ªët h∆°n** nh·ªù c·∫•u tr√∫c r√µ r√†ng\n",
    "- ‚úÖ **Gi·∫£m chi ph√≠ API** ƒë√°ng k·ªÉ\n",
    "\n",
    "**So s√°nh:**\n",
    "\n",
    "```json\n",
    "// JSON: 108 tokens\n",
    "{\n",
    "  \"users\": [\n",
    "    { \"id\": 1, \"name\": \"Alice\", \"role\": \"admin\" },\n",
    "    { \"id\": 2, \"name\": \"Bob\", \"role\": \"user\" }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "```toon\n",
    "// TOON: 72 tokens (gi·∫£m 33%)\n",
    "users[2]{id\tname\trole}:\n",
    "  1\tAlice\tadmin\n",
    "  2\tBob\tuser\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0143931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: So s√°nh TOON vs JSON\n",
    "def demo_toon_savings():\n",
    "    \"\"\"\n",
    "    Demo tr·ª±c quan v·ªÅ ti·∫øt ki·ªám token c·ªßa TOON\n",
    "    \"\"\"\n",
    "    sample_data = {\n",
    "        \"articles\": [\n",
    "            {\"id\": 1, \"symbol\": \"FPT\", \"title\": \"FPT c√¥ng b·ªë k·∫øt qu·∫£ kinh doanh\", \"price\": 120000},\n",
    "            {\"id\": 2, \"symbol\": \"VCB\", \"title\": \"Vietcombank tƒÉng tr∆∞·ªüng t√≠n d·ª•ng\", \"price\": 95000},\n",
    "            {\"id\": 3, \"symbol\": \"HPG\", \"title\": \"H√≤a Ph√°t m·ªü r·ªông s·∫£n xu·∫•t th√©p\", \"price\": 28500}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # JSON format\n",
    "    json_str = json.dumps(sample_data, ensure_ascii=False, indent=2)\n",
    "    json_tokens = len(json_str.encode('utf-8')) // 4  # ∆Ø·ªõc l∆∞·ª£ng ƒë∆°n gi·∫£n\n",
    "    \n",
    "    # TOON format\n",
    "    toon_str = to_toon_format(sample_data)\n",
    "    toon_tokens = len(toon_str.encode('utf-8')) // 4\n",
    "    \n",
    "    # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SO S√ÅNH TOON vs JSON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"\\nüìÑ JSON FORMAT:\")\n",
    "    print(f\"   ƒê·ªô d√†i: {len(json_str)} k√Ω t·ª±\")\n",
    "    print(f\"   ∆Ø·ªõc l∆∞·ª£ng: ~{json_tokens} tokens\")\n",
    "    print(f\"\\n{json_str[:200]}...\")\n",
    "    \n",
    "    print(\"\\nüìã TOON FORMAT:\")\n",
    "    print(f\"   ƒê·ªô d√†i: {len(toon_str)} k√Ω t·ª±\")\n",
    "    print(f\"   ∆Ø·ªõc l∆∞·ª£ng: ~{toon_tokens} tokens\")\n",
    "    print(f\"\\n{toon_str[:200]}...\")\n",
    "    \n",
    "    savings = ((json_tokens - toon_tokens) / json_tokens * 100) if json_tokens > 0 else 0\n",
    "    print(f\"\\nüí∞ TI·∫æT KI·ªÜM: ~{savings:.1f}% tokens\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Ch·∫°y demo (b·ªè comment d√≤ng d∆∞·ªõi ƒë·ªÉ xem)\n",
    "# demo_toon_savings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e355d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m ti·ªán √≠ch v·ªõi retry logic v√† API key rotation\n",
    "MAX_RETRIES = 5\n",
    "BASE_DELAY = 30\n",
    "\n",
    "def switch_api_key():\n",
    "    \"\"\"Chuy·ªÉn sang API key ti·∫øp theo trong danh s√°ch\"\"\"\n",
    "    global current_key_index, current_api_key, model, model_more_temperature, model_pro\n",
    "    \n",
    "    if len(GOOGLE_API_KEYS) <= 1:\n",
    "        return False\n",
    "    \n",
    "    current_key_index = (current_key_index + 1) % len(GOOGLE_API_KEYS)\n",
    "    current_api_key = GOOGLE_API_KEYS[current_key_index]\n",
    "    \n",
    "    # C·∫•u h√¨nh l·∫°i genai\n",
    "    genai.configure(api_key=current_api_key)\n",
    "    \n",
    "    # T·∫°o l·∫°i models v·ªõi key m·ªõi\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\", temperature=0.02)\n",
    "    model_more_temperature = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite\", temperature=0.1)\n",
    "    model_pro = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-exp-03-25\", temperature=0.1)\n",
    "    \n",
    "    print(f\"ƒê√£ chuy·ªÉn sang API key: ...{current_api_key[-8:]}\")\n",
    "    return True\n",
    "\n",
    "def invoke_chain_with_retry(chain, prompt, max_retries=MAX_RETRIES, base_delay=BASE_DELAY):\n",
    "    \"\"\"G·ªçi chain v·ªõi retry v√† auto-switch API key khi g·∫∑p l·ªói\"\"\"\n",
    "    retry_count = 0\n",
    "    key_switched = False\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = chain.invoke(prompt)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            error_msg = str(e).lower()\n",
    "            \n",
    "            # N·∫øu l·ªói quota/rate limit v√† ch∆∞a switch key, th·ª≠ switch\n",
    "            if not key_switched and (\"quota\" in error_msg or \"rate\" in error_msg or \"429\" in error_msg):\n",
    "                if switch_api_key():\n",
    "                    key_switched = True\n",
    "                    print(\"Th·ª≠ l·∫°i v·ªõi key m·ªõi...\")\n",
    "                    continue\n",
    "            \n",
    "            retry_count += 1\n",
    "            if retry_count > max_retries:\n",
    "                print(f\"ƒê√£ th·ª≠ {max_retries} l·∫ßn nh∆∞ng v·∫´n l·ªói: {e}\")\n",
    "                return None\n",
    "                \n",
    "            delay = base_delay * (2 ** (retry_count - 1))\n",
    "            print(f\"L·ªói: {e}. Th·ª≠ l·∫°i sau {delay}s (L·∫ßn {retry_count}/{max_retries})\")\n",
    "            time.sleep(delay)\n",
    "\n",
    "def to_toon_format(data):\n",
    "    \"\"\"Chuy·ªÉn d·ªØ li·ªáu sang TOON format\"\"\"\n",
    "    try:\n",
    "        import subprocess\n",
    "        json_data = json.dumps(data, ensure_ascii=False)\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            ['npx', '-y', '@toon-format/cli', '--delimiter', '\\t'],\n",
    "            input=json_data,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0 and result.stdout:\n",
    "            return result.stdout.strip()\n",
    "        else:\n",
    "            return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "    except Exception as e:\n",
    "        return json.dumps(data, ensure_ascii=False, indent=2)\n",
    "\n",
    "def combine_articles(df: pd.DataFrame, use_toon=True) -> str:\n",
    "    \"\"\"\n",
    "    K·∫øt h·ª£p c√°c b√†i b√°o th√†nh chu·ªói vƒÉn b·∫£n t·ªëi ∆∞u cho LLM\n",
    "    C·∫•u tr√∫c all_news.csv: postID, date, sentiment, taggedSymbols, combinedContent\n",
    "    \"\"\"\n",
    "    if use_toon and len(df) > 0:\n",
    "        try:\n",
    "            articles_data = []\n",
    "            for idx, row in df.iterrows():\n",
    "                combined = str(row.get('combinedContent', ''))\n",
    "                \n",
    "                # T√°ch title t·ª´ combinedContent\n",
    "                title = \"\"\n",
    "                content = combined\n",
    "                \n",
    "                if \"Title:\" in combined:\n",
    "                    parts = combined.split(\"Description:\", 1)\n",
    "                    title = parts[0].replace(\"Title:\", \"\").strip()\n",
    "                    if len(parts) > 1:\n",
    "                        content = parts[1].strip()\n",
    "                    title = parts[0].replace(\"Title:\", \"\").strip()\n",
    "                    if len(parts) > 1:\n",
    "                        content = parts[1].strip()[:500]\n",
    "                \n",
    "                article = {\n",
    "                    \"id\": int(row.get('postID', idx + 1)),\n",
    "                    \"taggedSymbols\": str(row.get('taggedSymbols', '[]')),\n",
    "                    \"title\": title if title else content[:100],  # D√πng 100 k√Ω t·ª± ƒë·∫ßu n·∫øu kh√¥ng c√≥ title\n",
    "                    \"content\": content\n",
    "                }\n",
    "                articles_data.append(article)\n",
    "            \n",
    "            # Chuy·ªÉn sang TOON format\n",
    "            toon_data = to_toon_format({\"articles\": articles_data})\n",
    "            \n",
    "            # Th√™m header gi·∫£i th√≠ch\n",
    "            return f\"```toon\\n{toon_data}\\n```\\n\\nL∆∞u √Ω: D·ªØ li·ªáu d√πng TOON format (ti·∫øt ki·ªám token). M·ªói d√≤ng: id, taggedSymbols, title, content.\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Kh√¥ng th·ªÉ d√πng TOON, d√πng format th√¥ng th∆∞·ªùng: {e}\")\n",
    "    \n",
    "    # Fallback: format text th√¥ng th∆∞·ªùng\n",
    "    articles = []\n",
    "    for idx, row in df.iterrows():\n",
    "        tagged_symbols = row.get('taggedSymbols', '[]')\n",
    "        combined = str(row.get('combinedContent', ''))\n",
    "        \n",
    "        article_text = f\"Tin {idx+1} (postID: {row.get('postID', 'N/A')}):\\n\"\n",
    "        article_text += f\"Tagged Symbols: {tagged_symbols}\\n\"\n",
    "        article_text += f\"N·ªôi dung: {combined[:500]}...\\n\"  # Gi·ªõi h·∫°n ƒë·ªô d√†i\n",
    "        articles.append(article_text)\n",
    "    \n",
    "    return \"\\n---\\n\".join(articles)\n",
    "\n",
    "def parse_summary_response(response, date, starting_index=1):\n",
    "    \"\"\"\n",
    "    Ph√¢n t√≠ch k·∫øt qu·∫£ t√≥m t·∫Øt t·ª´ LLM theo ƒë·ªãnh d·∫°ng [M√É]: [Ti√™u ƒë·ªÅ] | [N·ªôi dung]\n",
    "    \"\"\"\n",
    "    pattern = r'^([A-Z, ]*?):\\s*(.+?)\\s*\\|\\s*(.+)$'\n",
    "    response_text = str(response.content)\n",
    "    lines = response_text.splitlines()\n",
    "    articles = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "    \"\"\"Ph√¢n t√≠ch k·∫øt qu·∫£ t√≥m t·∫Øt t·ª´ LLM\"\"\"\n",
    "    pattern = r'^([A-Z, ]*?):\\s*(.+?)\\s*\\|\\s*(.+)$'\n",
    "    response_text = str(response.content)\n",
    "    lines = response_text.splitlines()\n",
    "    articles = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        match = re.match(pattern, line)\n",
    "        if match:\n",
    "            stock_codes, title, description = match.groups()\n",
    "            \n",
    "            # X·ª≠ l√Ω m√£ c·ªï phi·∫øu: lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a\n",
    "            stock_codes = stock_codes.strip()\n",
    "            \n",
    "            articles.append({\n",
    "                \"postID\": starting_index,\n",
    "                \"stockCodes\": stock_codes if stock_codes else \"\",\n",
    "                \"title\": title.strip(),                \n",
    "                \"description\": description.strip(),                \n",
    "                \"date\": date            \n",
    "                })            \n",
    "            starting_index += 1        \n",
    "            return pd.DataFrame(articles)\n",
    "        print(\"‚úì ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch v·ªõi TOON support\")\n",
    "        print(\"ƒê√£ ƒë·ªãnh nghƒ©a c√°c h√†m ti·ªán √≠ch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b2bdfad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ƒê√£ ƒë·ªãnh nghƒ©a h√†m summarize_news_with_stock_codes() v·ªõi TOON support\n"
     ]
    }
   ],
   "source": [
    "# H√†m ch√≠nh ƒë·ªÉ t√≥m t·∫Øt tin t·ª©c v·ªõi TOON format support\n",
    "def summarize_news_with_stock_codes(\n",
    "    csv_path=\"all_news/all_news.csv\",\n",
    "    output_path=\"summarized_news_with_stocks.csv\",\n",
    "    batch_size=5,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    max_articles_per_day=50,\n",
    "    use_toon=True  # B·∫≠t TOON format ƒë·ªÉ ti·∫øt ki·ªám token\n",
    "):\n",
    "    \"\"\"\n",
    "    T√≥m t·∫Øt tin t·ª©c t·ª´ all_news.csv v·ªõi t·ª± ƒë·ªông nh·∫≠n di·ªán m√£ c·ªï phi·∫øu\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "        ƒê∆∞·ªùng d·∫´n ƒë·∫øn file CSV ch·ª©a tin t·ª©c g·ªëc\n",
    "    output_path : str\n",
    "        ƒê∆∞·ªùng d·∫´n file CSV k·∫øt qu·∫£\n",
    "    batch_size : int\n",
    "        S·ªë ng√†y x·ª≠ l√Ω m·ªói batch (ƒë·ªÉ l∆∞u checkpoint)\n",
    "    start_date : str, optional\n",
    "        Ng√†y b·∫Øt ƒë·∫ßu (format: YYYY-MM-DD), n·∫øu None s·∫Ω x·ª≠ l√Ω t·ª´ ƒë·∫ßu\n",
    "    end_date : str, optional\n",
    "        Ng√†y k·∫øt th√∫c (format: YYYY-MM-DD), n·∫øu None s·∫Ω x·ª≠ l√Ω ƒë·∫øn cu·ªëi\n",
    "    max_articles_per_day : int\n",
    "        S·ªë l∆∞·ª£ng b√†i b√°o t·ªëi ƒëa m·ªói ng√†y (ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° context length)\n",
    "    use_toon : bool\n",
    "        S·ª≠ d·ª•ng TOON format ƒë·ªÉ ti·∫øt ki·ªám 30-60% token (m·∫∑c ƒë·ªãnh: True)\n",
    "    \"\"\"\n",
    "    print(f\"üìñ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ {csv_path}...\")\n",
    "    \n",
    "    # ƒê·ªçc d·ªØ li·ªáu\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"‚úì ƒê√£ ƒë·ªçc {len(df)} b√†i b√°o\")\n",
    "    \n",
    "    # Chuy·ªÉn ƒë·ªïi c·ªôt date sang datetime (c·ªôt ƒë√£ t√™n l√† 'date' s·∫µn)\n",
    "    df['parsed_date'] = pd.to_datetime(df['date'])\n",
    "    df['only_date'] = df['parsed_date'].dt.date\n",
    "    \n",
    "    # L·ªçc theo kho·∫£ng th·ªùi gian n·∫øu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh\n",
    "    if start_date:\n",
    "        start_dt = pd.to_datetime(start_date).date()\n",
    "        df = df[df['only_date'] >= start_dt]\n",
    "        print(f\"‚úì L·ªçc t·ª´ ng√†y {start_date}: c√≤n {len(df)} b√†i\")\n",
    "    \n",
    "    if end_date:\n",
    "        end_dt = pd.to_datetime(end_date).date()\n",
    "        df = df[df['only_date'] <= end_dt]\n",
    "        print(f\"‚úì L·ªçc ƒë·∫øn ng√†y {end_date}: c√≤n {len(df)} b√†i\")\n",
    "    \n",
    "    # S·∫Øp x·∫øp theo th·ªùi gian tƒÉng d·∫ßn\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Kh·ªüi t·∫°o DataFrame k·∫øt qu·∫£\n",
    "    df_summarized = pd.DataFrame(columns=[\"postID\", \"stockCodes\", \"title\", \"description\", \"date\"])\n",
    "    \n",
    "    # Nh√≥m theo ng√†y\n",
    "    date_groups = df.groupby(\"only_date\")\n",
    "    total_groups = len(date_groups)\n",
    "    \n",
    "    print(f\"\\nüìÖ S·∫Ω x·ª≠ l√Ω {total_groups} ng√†y\")\n",
    "    print(f\"‚öô Batch size: {batch_size} ng√†y/batch\")\n",
    "    print(f\"‚öô T·ªëi ƒëa {max_articles_per_day} b√†i/ng√†y\")\n",
    "    print(f\"‚öô TOON format: {'‚úì B·∫¨T (ti·∫øt ki·ªám 30-60% token)' if use_toon else '‚úó T·∫ÆT'}\\n\")\n",
    "    \n",
    "    # Ki·ªÉm tra checkpoint hi·ªán c√≥\n",
    "    if os.path.exists(output_path):\n",
    "        existing_df = pd.read_csv(output_path)\n",
    "        if len(existing_df) > 0:\n",
    "            last_date = pd.to_datetime(existing_df.iloc[-1]['date']).date()\n",
    "            print(f\"üîÑ Ph√°t hi·ªán checkpoint: ti·∫øp t·ª•c t·ª´ ng√†y {last_date}\")\n",
    "            df_summarized = existing_df\n",
    "            # B·ªè qua c√°c ng√†y ƒë√£ x·ª≠ l√Ω\n",
    "            date_groups = [(d, g) for d, g in date_groups if d > last_date]\n",
    "            total_groups = len(date_groups)\n",
    "            print(f\"‚úì C√≤n {total_groups} ng√†y c·∫ßn x·ª≠ l√Ω\\n\")\n",
    "    \n",
    "    # X·ª≠ l√Ω theo batch\n",
    "    current_idx = len(df_summarized) + 1\n",
    "    \n",
    "    for batch_idx in range(0, total_groups, batch_size):\n",
    "        batch_end = min(batch_idx + batch_size, total_groups)\n",
    "        batch_dates = list(date_groups)[batch_idx:batch_end]\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üì¶ BATCH {batch_idx//batch_size + 1}: X·ª≠ l√Ω ng√†y {batch_idx+1} ƒë·∫øn {batch_end}/{total_groups}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        batch_summaries = []\n",
    "        \n",
    "        for i, (date, group) in enumerate(batch_dates):\n",
    "            date_position = batch_idx + i + 1\n",
    "            \n",
    "            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng b√†i b√°o m·ªói ng√†y\n",
    "            if len(group) > max_articles_per_day:\n",
    "                print(f\"‚ö† Ng√†y {date} c√≥ {len(group)} b√†i, gi·ªõi h·∫°n xu·ªëng {max_articles_per_day} b√†i\")\n",
    "                group = group.head(max_articles_per_day)\n",
    "            \n",
    "            # K·∫øt h·ª£p c√°c b√†i b√°o (v·ªõi TOON n·∫øu ƒë∆∞·ª£c b·∫≠t)\n",
    "            combined_articles = combine_articles(group, use_toon=use_toon)\n",
    "            \n",
    "            # T·∫°o prompt\n",
    "            summary_prompt = {\n",
    "                \"articles_list\": combined_articles\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n[{date_position}/{total_groups}] üì∞ X·ª≠ l√Ω ng√†y {date} ({len(group)} b√†i b√°o)...\")\n",
    "            \n",
    "            # Retry v·ªõi nhi·ªÅu l·∫ßn th·ª≠\n",
    "            max_summary_retries = 10\n",
    "            summary_retry_count = 0\n",
    "            summary_df = pd.DataFrame()\n",
    "            \n",
    "            while summary_retry_count < max_summary_retries:\n",
    "                # Ch·ªçn model d·ª±a tr√™n s·ªë l·∫ßn retry\n",
    "                if summary_retry_count < 3:\n",
    "                    selected_chain = chain_summary\n",
    "                    model_name = \"flash-lite (temp=0.02)\"\n",
    "                elif summary_retry_count < 5:\n",
    "                    selected_chain = chain_summary_more_temp\n",
    "                    model_name = \"flash-lite (temp=0.1)\"\n",
    "                else:\n",
    "                    selected_chain = chain_summary_pro\n",
    "                    model_name = \"pro (temp=0.1)\"\n",
    "                \n",
    "                print(f\"   ü§ñ Model: {model_name} | Format: {'TOON' if use_toon else 'Text'}\")\n",
    "                \n",
    "                # G·ªçi API v·ªõi retry logic\n",
    "                summary_response = invoke_chain_with_retry(selected_chain, summary_prompt)\n",
    "                time.sleep(1)  # Rate limiting\n",
    "                \n",
    "                if summary_response is None:\n",
    "                    print(f\"   ‚ùå Kh√¥ng th·ªÉ t√≥m t·∫Øt ng√†y {date}\")\n",
    "                    break\n",
    "                \n",
    "                # Parse k·∫øt qu·∫£\n",
    "                date_str = f\"{date}T00:00:00+07:00\"\n",
    "                summary_df = parse_summary_response(summary_response, date_str, starting_index=current_idx)\n",
    "                \n",
    "                # Ki·ªÉm tra k·∫øt qu·∫£\n",
    "                if len(summary_df) > 0:\n",
    "                    print(f\"   ‚úì T√≥m t·∫Øt th√†nh {len(summary_df)} tin\")\n",
    "                    break\n",
    "                \n",
    "                summary_retry_count += 1\n",
    "                print(f\"   ‚ö† K·∫øt qu·∫£ r·ªóng, th·ª≠ l·∫°i l·∫ßn {summary_retry_count}/{max_summary_retries}\")\n",
    "                time.sleep(BASE_DELAY)\n",
    "            \n",
    "            # Th√™m v√†o k·∫øt qu·∫£ batch\n",
    "            if len(summary_df) > 0:\n",
    "                current_idx += len(summary_df)\n",
    "                batch_summaries.append(summary_df)\n",
    "            else:\n",
    "                print(f\"   ‚ùå Th·∫•t b·∫°i sau {max_summary_retries} l·∫ßn th·ª≠ cho ng√†y {date}\")\n",
    "        \n",
    "        # L∆∞u checkpoint sau m·ªói batch\n",
    "        if batch_summaries:\n",
    "            batch_df = pd.concat(batch_summaries, ignore_index=True)\n",
    "            df_summarized = pd.concat([df_summarized, batch_df], ignore_index=True)\n",
    "            \n",
    "            # L∆∞u file\n",
    "            df_summarized.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            checkpoint_num = batch_idx // batch_size + 1\n",
    "            print(f\"\\nüíæ ƒê√£ l∆∞u checkpoint {checkpoint_num}: {len(df_summarized)} tin t√≥m t·∫Øt\")\n",
    "    \n",
    "    # L∆∞u file cu·ªëi c√πng\n",
    "    df_summarized.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úÖ HO√ÄN TH√ÄNH!\")\n",
    "    print(f\"üìä T·ªïng s·ªë tin t√≥m t·∫Øt: {len(df_summarized)}\")\n",
    "    print(f\"üíæ ƒê√£ l∆∞u v√†o: {output_path}\")\n",
    "    if use_toon:\n",
    "        print(f\"üí∞ ∆Ø·ªõc t√≠nh ti·∫øt ki·ªám: 30-60% token nh·ªù TOON format\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return df_summarized\n",
    "\n",
    "print(\"‚úì ƒê√£ ƒë·ªãnh nghƒ©a h√†m summarize_news_with_stock_codes() v·ªõi TOON support\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cab09",
   "metadata": {},
   "source": [
    "## üöÄ Ch·∫°y t√≥m t·∫Øt tin t·ª©c\n",
    "\n",
    "### L·ª£i √≠ch khi d√πng TOON:\n",
    "- üí∞ **Gi·∫£m 30-60% chi ph√≠ API** (√≠t token h∆°n)\n",
    "- ‚ö° **Ph·∫£n h·ªìi nhanh h∆°n** (input nh·ªè g·ªçn)\n",
    "- üéØ **LLM hi·ªÉu t·ªët h∆°n** (c·∫•u tr√∫c r√µ r√†ng)\n",
    "\n",
    "### C√°ch s·ª≠ d·ª•ng:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69baf38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ ƒêang ƒë·ªçc d·ªØ li·ªáu t·ª´ all_news/all_news.csv...\n",
      "‚úì ƒê√£ ƒë·ªçc 241990 b√†i b√°o\n",
      "‚úì ƒê√£ ƒë·ªçc 241990 b√†i b√°o\n",
      "‚úì L·ªçc t·ª´ ng√†y 2024-01-01: c√≤n 152334 b√†i\n",
      "\n",
      "üìÖ S·∫Ω x·ª≠ l√Ω 670 ng√†y\n",
      "‚öô Batch size: 5 ng√†y/batch\n",
      "‚öô T·ªëi ƒëa 50 b√†i/ng√†y\n",
      "‚öô TOON format: ‚úì B·∫¨T (ti·∫øt ki·ªám 30-60% token)\n",
      "\n",
      "üîÑ Ph√°t hi·ªán checkpoint: ti·∫øp t·ª•c t·ª´ ng√†y 2024-07-13\n",
      "‚úì C√≤n 475 ng√†y c·∫ßn x·ª≠ l√Ω\n",
      "\n",
      "\n",
      "============================================================\n",
      "üì¶ BATCH 1: X·ª≠ l√Ω ng√†y 1 ƒë·∫øn 5/475\n",
      "============================================================\n",
      "‚ö† Ng√†y 2024-07-14 c√≥ 168 b√†i, gi·ªõi h·∫°n xu·ªëng 50 b√†i\n",
      "\n",
      "[1/475] üì∞ X·ª≠ l√Ω ng√†y 2024-07-14 (50 b√†i b√°o)...\n",
      "   ü§ñ Model: flash-lite (temp=0.02) | Format: TOON\n",
      "‚úì L·ªçc t·ª´ ng√†y 2024-01-01: c√≤n 152334 b√†i\n",
      "\n",
      "üìÖ S·∫Ω x·ª≠ l√Ω 670 ng√†y\n",
      "‚öô Batch size: 5 ng√†y/batch\n",
      "‚öô T·ªëi ƒëa 50 b√†i/ng√†y\n",
      "‚öô TOON format: ‚úì B·∫¨T (ti·∫øt ki·ªám 30-60% token)\n",
      "\n",
      "üîÑ Ph√°t hi·ªán checkpoint: ti·∫øp t·ª•c t·ª´ ng√†y 2024-07-13\n",
      "‚úì C√≤n 475 ng√†y c·∫ßn x·ª≠ l√Ω\n",
      "\n",
      "\n",
      "============================================================\n",
      "üì¶ BATCH 1: X·ª≠ l√Ω ng√†y 1 ƒë·∫øn 5/475\n",
      "============================================================\n",
      "‚ö† Ng√†y 2024-07-14 c√≥ 168 b√†i, gi·ªõi h·∫°n xu·ªëng 50 b√†i\n",
      "\n",
      "[1/475] üì∞ X·ª≠ l√Ω ng√†y 2024-07-14 (50 b√†i b√°o)...\n",
      "   ü§ñ Model: flash-lite (temp=0.02) | Format: TOON\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 30s (L·∫ßn 1/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 30s (L·∫ßn 1/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 60s (L·∫ßn 2/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 60s (L·∫ßn 2/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 120s (L·∫ßn 3/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 120s (L·∫ßn 3/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 240s (L·∫ßn 4/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 240s (L·∫ßn 4/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 480s (L·∫ßn 5/5)\n",
      "L·ªói: Invalid argument provided to Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]. Th·ª≠ l·∫°i sau 480s (L·∫ßn 5/5)\n"
     ]
    }
   ],
   "source": [
    "# Ch·∫°y t√≥m t·∫Øt tin t·ª©c v·ªõi TOON format\n",
    "# TOON gi√∫p gi·∫£m 30-60% token ‚Üí Ti·∫øt ki·ªám chi ph√≠ API ƒë√°ng k·ªÉ!\n",
    "\n",
    "result_df = summarize_news_with_stock_codes(\n",
    "    csv_path=\"all_news/all_news.csv\",\n",
    "    output_path=\"summarized_news_with_stocks.csv\",\n",
    "    batch_size=5,\n",
    "    start_date=\"2024-01-01\",\n",
    "    end_date=None,\n",
    "    use_toon=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d416668",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è C√°c t√πy ch·ªçn n√¢ng cao\n",
    "\n",
    "B·∫°n c√≥ th·ªÉ t√πy ch·ªânh c√°c tham s·ªë:\n",
    "\n",
    "| Tham s·ªë | M√¥ t·∫£ | Gi√° tr·ªã m·∫∑c ƒë·ªãnh |\n",
    "|---------|-------|------------------|\n",
    "| `use_toon` | B·∫≠t TOON format (ti·∫øt ki·ªám 30-60% token) | `True` |\n",
    "| `batch_size` | S·ªë ng√†y x·ª≠ l√Ω m·ªói l·∫ßn (checkpoint) | `5` |\n",
    "| `max_articles_per_day` | Gi·ªõi h·∫°n b√†i b√°o/ng√†y | `50` |\n",
    "| `start_date` | Ng√†y b·∫Øt ƒë·∫ßu (YYYY-MM-DD) | `None` (t·ª´ ƒë·∫ßu) |\n",
    "| `end_date` | Ng√†y k·∫øt th√∫c (YYYY-MM-DD) | `None` (ƒë·∫øn cu·ªëi) |\n",
    "\n",
    "**Khi n√†o n√™n t·∫Øt TOON?**\n",
    "- D·ªØ li·ªáu kh√¥ng ƒë·ªìng nh·∫•t (m·ªói b√†i c√≥ c·∫•u tr√∫c kh√°c nhau)\n",
    "- ƒê√£ quen v·ªõi JSON format\n",
    "- Debugging (JSON d·ªÖ ƒë·ªçc h∆°n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d0fad5",
   "metadata": {},
   "source": [
    "## Xem k·∫øt qu·∫£\n",
    "\n",
    "Xem m·ªôt s·ªë m·∫´u tin t·ª©c ƒë√£ t√≥m t·∫Øt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem k·∫øt qu·∫£ t√≥m t·∫Øt\n",
    "print(f\"T·ªïng s·ªë tin ƒë√£ t√≥m t·∫Øt: {len(result_df)}\")\n",
    "print(f\"\\nC√°c c·ªôt: {result_df.columns.tolist()}\")\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"M·∫™U 10 TIN T√ìM T·∫ÆT ƒê·∫¶U TI√äN:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for idx, row in result_df.head(10).iterrows():\n",
    "    stock_codes = row['stockCodes'] if row['stockCodes'] else \"Kh√¥ng c√≥ m√£\"\n",
    "    print(f\"[{row['postID']}] {stock_codes}\")\n",
    "    print(f\"üìÖ {row['date']}\")\n",
    "    print(f\"üìå {row['title']}\")\n",
    "    print(f\"üìù {row['description']}\")\n",
    "    print(f\"{'-'*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66800bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ph√¢n t√≠ch th·ªëng k√™ m√£ c·ªï phi·∫øu\n",
    "print(\"üìä TH·ªêNG K√ä M√É C·ªî PHI·∫æU ƒê∆Ø·ª¢C ƒê·ªÄ C·∫¨P\\n\")\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng tin c√≥ m√£ v√† kh√¥ng c√≥ m√£\n",
    "has_stock = result_df[result_df['stockCodes'] != ''].shape[0]\n",
    "no_stock = result_df[result_df['stockCodes'] == ''].shape[0]\n",
    "\n",
    "print(f\"‚úì Tin c√≥ m√£ c·ªï phi·∫øu: {has_stock} ({has_stock/len(result_df)*100:.1f}%)\")\n",
    "print(f\"‚úì Tin kh√¥ng c√≥ m√£: {no_stock} ({no_stock/len(result_df)*100:.1f}%)\")\n",
    "\n",
    "# T√°ch c√°c m√£ c·ªï phi·∫øu v√† ƒë·∫øm t·∫ßn su·∫•t\n",
    "all_stocks = []\n",
    "for codes in result_df['stockCodes']:\n",
    "    if codes:\n",
    "        # T√°ch c√°c m√£ b·∫±ng d·∫•u ph·∫©y\n",
    "        stocks = [s.strip() for s in codes.split(',') if s.strip()]\n",
    "        all_stocks.extend(stocks)\n",
    "\n",
    "if all_stocks:\n",
    "    from collections import Counter\n",
    "    stock_counter = Counter(all_stocks)\n",
    "    \n",
    "    print(f\"\\nüìà TOP 20 M√É C·ªî PHI·∫æU ƒê∆Ø·ª¢C ƒê·ªÄ C·∫¨P NHI·ªÄU NH·∫§T:\\n\")\n",
    "    for i, (stock, count) in enumerate(stock_counter.most_common(20), 1):\n",
    "        print(f\"{i:2d}. {stock:6s} - {count:4d} l·∫ßn\")\n",
    "else:\n",
    "    print(\"\\n‚ö† Ch∆∞a c√≥ m√£ c·ªï phi·∫øu n√†o ƒë∆∞·ª£c nh·∫≠n di·ªán\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838e9618",
   "metadata": {},
   "source": [
    "## C√°c t√≠nh nƒÉng n√¢ng cao\n",
    "\n",
    "### T√¨m ki·∫øm tin t·ª©c theo m√£ c·ªï phi·∫øu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517c9968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√¨m ki·∫øm tin t·ª©c theo m√£ c·ªï phi·∫øu ( sau n√†y d√πng th√¨ c√≥ c√°i m√† d√πng )\n",
    "def search_by_stock_code(df, stock_code):\n",
    "    \"\"\"\n",
    "    T√¨m t·∫•t c·∫£ tin t·ª©c li√™n quan ƒë·∫øn m·ªôt m√£ c·ªï phi·∫øu\n",
    "    \"\"\"\n",
    "    stock_code = stock_code.upper().strip()\n",
    "    mask = df['stockCodes'].str.contains(stock_code, case=False, na=False)\n",
    "    results = df[mask]\n",
    "    \n",
    "    print(f\"üîç T√¨m th·∫•y {len(results)} tin t·ª©c v·ªÅ m√£ {stock_code}\\n\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for idx, row in results.iterrows():\n",
    "        print(f\"\\n[{row['postID']}] {row['stockCodes']}\")\n",
    "        print(f\"üìÖ {row['date']}\")\n",
    "        print(f\"üìå {row['title']}\")\n",
    "        print(f\"üìù {row['description']}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# V√≠ d·ª•: T√¨m tin v·ªÅ FPT\n",
    "# search_by_stock_code(result_df, \"FPT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
